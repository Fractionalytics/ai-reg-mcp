{
  "law": {
    "law_id": "CA-FEHA-AI",
    "jurisdiction": "CA",
    "common_name": "California FEHA AI/ADS Employment Regulations",
    "official_citation": "2 Cal. Code Regs. §§ 11008.1, 11009, 11016, 11017, 11023, 11081",
    "status": "effective",
    "effective_date": "2025-10-01",
    "last_updated": "2026-02-13",
    "source_url": "https://calcivilrights.ca.gov/wp-content/uploads/sites/32/2025/06/Final-Text-regulations-automated-employment-decision-systems.pdf",
    "summary": "California Civil Rights Council regulations clarifying that the Fair Employment and Housing Act (FEHA) anti-discrimination protections apply to automated decision systems (ADS) in employment. Establishes definitions for ADS and AI, prohibits discrimination through ADS, requires 4-year recordkeeping, incentivizes anti-bias testing as an affirmative defense, and extends liability to employer agents including AI vendors.",

    "applicability": {
      "who_it_applies_to": ["employer", "employment_agency", "labor_organization", "agent"],
      "definitions": {
        "employer": "Any person regularly employing five or more persons, or any person acting as an agent of an employer, directly or indirectly. Includes the state of California and any political or civil subdivision of the state and cities.",
        "automated_decision_system": "A computational process that makes a decision or facilitates human decision making regarding an employment benefit. May be derived from and/or use artificial intelligence, machine-learning, algorithms, statistics, and/or other data processing techniques.",
        "artificial_intelligence": "A machine-based system that infers, from the input it receives, how to generate outputs, such as predictions, content, recommendations, or decisions, which can influence physical or virtual environments.",
        "agent": "Any person acting directly or indirectly in the interest of an employer, or anyone acting on behalf of an employer to exercise a function traditionally exercised by the employer.",
        "proxy": "A characteristic or category closely correlated with a protected characteristic under FEHA."
      },
      "scope_conditions": "Applies to employers with 5 or more employees working anywhere and at least one employee located within California. Covers all employment benefits including recruitment, hiring, promotion, training, pay, benefits, leave, discipline, and termination decisions made using or facilitated by automated decision systems.",
      "exemptions": [
        "Employers with fewer than 5 employees",
        "ADS used exclusively for security or fraud prevention (narrow exception)",
        "Anti-bias testing provides potential affirmative defense but is not a complete exemption"
      ],
      "geographic_trigger": "Employer with at least 5 employees and at least one employee in California, OR making employment decisions affecting California residents"
    },

    "obligations": [
      {
        "obligation_id": "CA-FEHA-AI-OBL-001",
        "applies_to": "employer",
        "category": "transparency",
        "requirement_text": "It is an unlawful employment practice to use an automated decision-system or selection criteria that discriminates against applicants or employees on the basis of any protected characteristic under FEHA, including race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, or military and veteran status.",
        "plain_language": "You cannot use AI or automated systems in hiring, promotion, or other employment decisions if they discriminate against people based on protected characteristics.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11009(f)"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-002",
        "applies_to": "employer",
        "category": "bias_testing",
        "requirement_text": "An employer may defend against a claim of discrimination based on the use of an ADS by demonstrating that it conducted anti-bias testing or similar proactive efforts to avoid unlawful discrimination. Factors include the quality, efficacy, recency, and scope of such testing, whether testing was conducted before and after adoption, and whether the employer took reasonable steps to address potential discrimination identified through testing.",
        "plain_language": "To defend against discrimination claims, you should conduct anti-bias testing on your AI systems before and after deployment and take action on the findings. This is not mandatory but provides a potential affirmative defense.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11009(f)(2)"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-003",
        "applies_to": "employer",
        "category": "documentation",
        "requirement_text": "Employers shall preserve all personnel and employment records, including automated-decision system data, for a period of four years from the date of the record's creation or the date of the personnel action involved, whichever occurs later.",
        "plain_language": "You must keep all records related to automated decision systems, including data inputs, outputs, and decisions, for at least 4 years (increased from 2 years).",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11023"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-004",
        "applies_to": "employer",
        "category": "documentation",
        "requirement_text": "Automated-decision system data that must be preserved includes all information used in, resulting from, or related to the application of an ADS, including dataset descriptors, scoring outputs, audit findings, and any data used to train, test, or customize the system.",
        "plain_language": "Your recordkeeping must include comprehensive ADS data: training datasets, test results, scoring outputs, audit reports, and system configurations.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11023"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-005",
        "applies_to": "employer",
        "category": "bias_testing",
        "requirement_text": "Employers must ensure that ADS selection criteria do not have an adverse impact on applicants or employees based on protected characteristics unless the criteria are job-related and consistent with business necessity, and no alternative selection criteria exist that would have a less discriminatory impact.",
        "plain_language": "Your AI systems cannot have a disparate impact on protected groups unless you can prove the criteria are essential for the job and there's no less discriminatory alternative.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11017(e)"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-006",
        "applies_to": "employer",
        "category": "human_oversight",
        "requirement_text": "Employers must provide reasonable accommodations for disability and religious creed when ADS measures abilities, analyzes physical or mental characteristics, or evaluates traits related to job performance that may disadvantage individuals with disabilities or religious practices.",
        "plain_language": "When your AI system tests abilities or analyzes characteristics, you must provide reasonable accommodations for disabilities and religious practices (e.g., alternative tests, different assessment methods).",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. §§ 11016(c)(5), 11016(d)(1)"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-007",
        "applies_to": "employer",
        "category": "transparency",
        "requirement_text": "Employers are prohibited from using automated-decision systems to inquire about or screen for criminal history before making a conditional offer of employment.",
        "plain_language": "You cannot use AI to screen out job applicants based on criminal history until after you've made a conditional job offer.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11017"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-008",
        "applies_to": "employer",
        "category": "transparency",
        "requirement_text": "Employers may not use ADS to conduct medical or psychological examinations of applicants before making a conditional offer of employment.",
        "plain_language": "You cannot use AI to conduct medical or psychological assessments (including analyzing tone of voice, facial expressions, or other health-related indicators) before making a conditional job offer.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11008.1"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-009",
        "applies_to": "employer",
        "category": "transparency",
        "requirement_text": "Employers must avoid using ADS that rely on proxies—characteristics or categories closely correlated with protected characteristics—that result in discrimination.",
        "plain_language": "Your AI systems cannot use proxy variables (like ZIP codes, names, or other factors that correlate with protected characteristics) if they lead to discrimination.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11008(l)"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-010",
        "applies_to": "agent",
        "category": "governance",
        "requirement_text": "Agents of employers, including AI vendors and service providers who conduct recruitment, screening, hiring, promotion, or compensation decisions on behalf of employers, are subject to FEHA's anti-discrimination requirements and can be held liable for discriminatory ADS practices.",
        "plain_language": "If you're an AI vendor or consultant providing employment decision tools, you can be held directly liable for discrimination under FEHA just like the employer.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11009"
      },
      {
        "obligation_id": "CA-FEHA-AI-OBL-011",
        "applies_to": "employment_agency",
        "category": "transparency",
        "requirement_text": "Employment agencies and labor organizations are prohibited from using automated-decision systems that discriminate on the basis of protected characteristics in job referrals, union membership, or other employment benefits.",
        "plain_language": "If you're an employment agency or union, you cannot use AI systems that discriminate in job referrals, membership decisions, or other benefits.",
        "deadline": "2025-10-01",
        "recurring": true,
        "frequency": "ongoing",
        "citation": "2 Cal. Code Regs. § 11009"
      }
    ],

    "penalties": {
      "enforcing_body": "California Civil Rights Department (CRD)",
      "private_right_of_action": true,
      "penalty_range": "Unlimited compensatory and punitive damages, back pay, front pay, reinstatement, attorney's fees, and costs. Administrative penalties determined by CRD.",
      "cure_period": false,
      "cure_period_days": null,
      "notes": "FEHA provides both administrative enforcement through the California Civil Rights Department and a private right of action. Complainants must first file with CRD and obtain a right-to-sue letter before filing in court. FEHA offers unlimited compensatory and punitive damages (unlike federal laws which cap damages). These regulations clarify existing FEHA enforcement applies to ADS discrimination."
    },

    "safe_harbors": [
      {
        "description": "Anti-bias testing affirmative defense: Employers who conduct rigorous, timely, repeatable, and transparent anti-bias testing before and after ADS adoption, and take reasonable steps to address identified discrimination risks, may establish an affirmative defense against discrimination claims.",
        "framework_reference": "Anti-bias testing and proactive discrimination prevention measures",
        "citation": "2 Cal. Code Regs. § 11009(f)(2)"
      },
      {
        "description": "Job-related business necessity defense: If ADS selection criteria have disparate impact but are proven to be job-related and consistent with business necessity, and no less discriminatory alternative exists, this may serve as a defense.",
        "framework_reference": "FEHA disparate impact standard",
        "citation": "2 Cal. Code Regs. § 11017(e)"
      }
    ],

    "cross_references": [
      {
        "related_law": "CO-SB24-205",
        "relationship": "similar_obligation",
        "category": "risk_assessment",
        "notes": "Colorado AI Act requires impact assessments and risk management for high-risk AI systems. California FEHA regulations incentivize but do not mandate anti-bias testing. Colorado provides NIST AI RMF safe harbor; California does not reference NIST. Colorado has 60-day cure period; California FEHA does not."
      },
      {
        "related_law": "NYC-LL144",
        "relationship": "similar_obligation",
        "category": "bias_testing",
        "notes": "NYC Local Law 144 mandates annual independent bias audits with public disclosure. California incentivizes but does not mandate anti-bias testing and has no public disclosure requirement, allowing testing under attorney-client privilege. California's 'substantial factor' test is broader than NYC's scope."
      },
      {
        "related_law": "CA-CCPA-ADMT",
        "relationship": "complementary",
        "category": "risk_assessment",
        "notes": "CCPA ADMT regulations (enforced by CPPA) address automated decision-making broadly including employment, with focus on consumer privacy rights. FEHA AI regulations (enforced by CRD) specifically address employment discrimination. Both apply to California employers but have different enforcement bodies and remedies."
      }
    ],

    "change_log": [
      {
        "date": "2024-05-07",
        "change_type": "new_law",
        "description": "California Civil Rights Council published proposed regulations on automated employment decision systems under FEHA."
      },
      {
        "date": "2025-03-17",
        "change_type": "amendment",
        "description": "Civil Rights Council released final unmodified text of proposed employment regulations regarding automated decision systems after public comment period."
      },
      {
        "date": "2025-06-27",
        "change_type": "new_law",
        "description": "California Office of Administrative Law approved final regulations. Civil Rights Council secured approval for regulations to protect against employment discrimination related to AI."
      },
      {
        "date": "2025-06-30",
        "change_type": "new_law",
        "description": "Civil Rights Council announced official approval and publication of final regulations on automated employment decision systems."
      },
      {
        "date": "2025-10-01",
        "change_type": "new_law",
        "description": "FEHA automated decision system regulations became effective. All covered employers must comply with ADS anti-discrimination requirements and 4-year recordkeeping obligations."
      }
    ]
  }
}
